# 语音合成算法

## 1 End-to-End TTS Before Tacotron
- First step toward End-to-End Parametric TTS
  - 输入：phoneome 音素
  - 输出：acoustic feature for STRAIGHT (vocoder)
- Char2Wav
  - 输入：character
  - 输出：acoustic feature for SampleRNN (vocoder)
  

## 2 Tacotron
参考论文：[Tacotron: Towards End-to-End Speech Synthesis](https://arxiv.org/abs/1703.10135)  
来源：Interspeech 2017  
发表时间：2017.4.6  

Taco这个名字只是因为该论文的一部分作者喜欢吃Taco而得来，本来名字叫Talkotron。  
输入：character
输出：(linear) spectrogram
Tacotron网络框架  
Encoder + Attention + Decoder
![image](https://user-images.githubusercontent.com/40049927/136914526-1e0e4173-181f-4241-8e1b-fb0b9621282a.png)

### Encoder = Grapheme-to-phoneme 字母→编码器→音素


### Attention
attention让模型自动学出每一个tone的embedding（encoder的输出）在decoder中能够产生多长的声音信号。

### Decoder 
作者使用了两种decoder：`attention RNN`和`output RNN`。`attention RNN`负责生成`query vector`作为`attention`模块的输入，`attention`模块生成`context vector`，最后`output RNN`将`query vector`和`context vector`组合在一起作为输入。  

最后RNN输出的是mel-spectrogram而不是spectrogram是出于计算量的原因。另外一个用来缩减计算量的做法是每个decoder step预测多个(r个)frame，且作者发现这样做还可以加速模型的收敛。
teacher forcing

end? 是否需要结束
是一个二分类器，用来结束decoder的解码操作，结束生成音频。

### CBHG
`CBHG`:(1-D convolution bank + highway network + bidirectional GRU)  
CBHG从序列中提取出高层次模块，卷积+highway+残差链接+双向GRU的组合，输入序列，输出同样也是序列。
 
### Pre-net
作者设计Pre-net的意图是让它成为一个bottleneck layer来提升模型的泛化能力，以加快收敛速度。Pre-net由全连接层+Dropout组成。

### Dropout
在模型推理阶段，Dropout需要保留。因为如果Droput去掉，模型在进行样本点生成的时候，会贪心地选择概率最大的样本点，这样会导致一些极其不自然的声音出现。  

## 3 Tacotron2
参考论文：[Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions](https://arxiv.org/abs/1712.05884)  
来源：ICASSP 2018  
发表时间：2018.2.16  


Tacotron2和Tacotron的主要不同在于：
- 不使用CBHG，而是使用普通的LSTM和Convolution layer
- decoder每一步只生成一个frame
- 增加post-net，即一个5层CNN来精调mel-spectrogram
- 使用Wavenet作为声码器

## 4 Transformer TTS
参考论文：[Neural Speech Synthesis with Transformer Network](https://arxiv.org/abs/1809.08895)  
来源：ICASSP 2018  
发表时间：2019.1.30  

## 5 FastSpeech - 基于tTransformer的end-to-end TTS模型
参考论文：[FastSpeech: Fast, Robust and Controllable Text to Speech](https://arxiv.org/pdf/1905.09263.pdf)  
来源：ICASSP 2018  
发表时间：2019.1.30  

Tacotron2是一个自回归模型，合成速度慢。基于Transformer的FastSpeech在保持合成高质量语音的同时大幅提高了合成速度。

## 6 FastSpeech 2
参考论文：[FastSpeech 2: Fast and High-Quality End-to-End Text to Speech](https://arxiv.org/abs/2006.04558)  
来源：ICLR 2021  
发表时间：2021.3.4  

FastSpeech存在着训练时间长等缺点。FastSpeech2改进了这些问题，使得模型的训练速度加快了3倍，且可以合成出音质比Tacotron更高的语音。

