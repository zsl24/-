# 语音分离算法

## Deep Clustering
K-means不需要训练，我们在Deep Clustering只需要训练Embedding Generation。用两个人的数据训练，推理时也可以分离三个人的声音。  
 
### Embedding Generation
![image](https://user-images.githubusercontent.com/40049927/137741674-6045f0dd-b8dd-4afa-a04b-687e19b181f3.png)

`Embedding Generation` 将语谱图(D×T)每个频率点变换成一个一维向量(1×1×A)，一共有D×T个向量，对这些向量进行K-means聚类。**K-means Clutering** 设置k为声源数量。
对于每个grid进行聚类，分到第一群的grid，分给第一个声源，分到第二群的grid，分给第二个声源。  

`Embedding Generation`的训练目标是：**对于来自同一个声源的grids，我们希望其对应的Embedding之后的向量之间距离的距离会非常近，而来自不同声源的grids，其Embedding的距离要尽量地远。**  

## Permutation Invariant Training (PIT)
**腾讯**  
![image](https://user-images.githubusercontent.com/40049927/137748099-5c917f9f-68d1-4303-bcc9-c7d703000c90.png)


## TasNet
![image](https://user-images.githubusercontent.com/40049927/137748137-066d5f81-c177-45e2-b5aa-2f8407ea8fbe.png)

### Encoder 和 Decoder
![image](https://user-images.githubusercontent.com/40049927/137748550-f725d184-d22b-416b-8e0a-6666f105ec86.png)
Encoder将16个音频采样点通过线性变换编码成512×1的特征向量，Deocder将512×1的特征向量解码成16个音频采样点。  

### Separator

