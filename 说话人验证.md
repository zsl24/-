# 说话人验证 Speaker Verification

`说话人识别` Speaker Recognition/ Identification：判断这段声音信号是谁说的，经典的分类问题  
`说话人验证` Speaker Verification：判断两段声音是不是同一个人讲的  
`说话人分段标记` Speaker Diarization: 在一段语音中，谁在何时说话(Segmentation + Clustering)  
Equal Error Rate (EER)  
False Negative (FN) Rate  
False Positive (FP) Rate  

说话人验证分为三个步骤：  
Stage 1. Development: 训练出可以产生正确speaker embedding的模型  
Stage 2. Enrollment: 银行客服注册语者验证服务时，要求用户说两句话，并生成对应的`speaker embedding`作为以后推理的reference
Stage 3. Evaluation: 在日后使用语者验证服务时，比较两个`speaker embedding`
(Stage2和Stage3的语者不会用于Stage1的模型训练当中)  

## Speaker Embedding 说话人嵌入

说话人嵌入将语音映射到语者空间，得到一个表示语者身份的向量。

### i-vecotr
(最后一个被Deeplearning打败的模型，一直坚持到2017年)
identity vector
![image](https://user-images.githubusercontent.com/40049927/139088927-16577f8e-cb36-471c-abee-c153cd5e367a.png)  

### d-vector
d - deep learning  

训练DNN用于`speaker recognition`。  
抽取最后一个隐藏层的vector作为`speaker embedding`。
将这个语音进行分割，对每个片段计算一个vector，然后将所有计算出来的vector求平均，最后就得到`d-vector`。  

d-vector 跟 i-vector 效果差不多

### x-vector
![Uploading image.png…]()  

### Attention Mechanism

利用attention学习weight，再进行加权求和得到最后的`speaker embedding`。

### NetVLAD

## End-to-end 说话人验证
将speaker embedding和计算相似度融合到一个end-to-end的模型，共同训练。  


