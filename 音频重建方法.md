# 音频重建方法汇总 - 声码器 Vocoder

音频重建方法可以分成两种：
- 传统方法 Rule based
- 神经网络方法 Deep learning based
   通常，基于神经网络的声码器要不就是推理速度慢，要不就是很难训练。未来的工作就是要设计出一款声码器，既容易训练，又能够快速地生成高质量
推理速度：
Mel-GAN WveFlow WaveGlow
 
## 声码器对比
| Vocoder                      | 训练速度 | 推理速度CPU(kHz) | 推理速度GPU(kHz) | 推理速率比率 (推理速率/实时速率) | 参数量(M) | 特点                             |
| ---------------------------- | -------- | ---------------- | ---------------- | -------------------------------- | --------- | -------------------------------- |
| Multi-band MelGAN            |          |                  |                  | 33(CPU)                          | 1.91      | 比实时更快                       |
| MelGAN                       |          | 51.9             | 2500             | 100(GPU),2(CPU)                  | 4.26      | 比实时更快                       |
| LPCNet                       |          |                  |                  |                                  |           |                                  |
| WaveFlow                     |          |                  | 939              | 42.6(GPU)                        | 5.91      | 比实时更快，模型比WaveGlow小15倍 |
| WaveGlow                     |          | 1.58             | 223              | 32.5                             | 87.9      | 比实时更快，模型很大，很难训练   |
| WaveRNN                      |          |                  | 30               | <1                               |           |                                  |
| FFTNet                       |          |                  |                  |                                  |           |                                  |
| WaveNet                      |          | 0.0627           | 0.11             | 0.006                            | 24.7      |                                  |
| Highly optimized Griffin-Lim |          |                  |                  | 507                              |           |                                  |



## 1 传统方法

### Griffin-Lim 算法

### Deep Griffin-Lim
参考论文：[Fast Signal Reconstruction from Magnitude STFT Spectrogram based on Spectrogram Consistency](http://dafx10.iem.at/proceedings/papers/LeRouxKameokaOnoSagayama_DAFx10_P24.pdf)  
来源：13th Int. Conference on Digital Audio Effects (DAFx-10), Graz, Austria , September 6-10, 2010

## 2 神经网络方法

### WaveNet
**谷歌**  
参考论文：[Efficient Neural Audio Synthesis](https://arxiv.org/abs/1802.08435)  
来源：  
发表时间：2018.6.25  

### Parallel WaveNet

### FFTNet

参考论文：[FFTNet: a Real-Time Speaker-Dependent Neural Vocoder](https://gfx.cs.princeton.edu/pubs/Jin_2018_FAR/fftnet-jin2018.pdf)  
来源：ICASSP 2018  
发表时间：2016.9.12  
github地址：https://github.com/azraelkuan/FFTNet  


### WaveRNN
**谷歌**  
参考论文：[Efficient Neural Audio Synthesis](https://arxiv.org/abs/1802.08435)  
来源：  
发表时间：2016.9.12  

### 2.2 WaveGlow  
**英伟达**  
参考论文：[WaveGlow: A Flow-based Generative Network for Speech Synthesis](https://arxiv.org/abs/1811.00002)  
来源：ICASSP 2019  
发表时间：2018.10.31  
github地址：https://github.com/NVIDIA/waveglow  
WaveGlow结合了Glow以及WaveNet的思想，从而能够完成更加快速的高质量语音合成，摒弃了自回归模型。文章中的实验结果表明，其生成的语音质量和WaveNet一样好。  
但是WaveGlow非常难训练，原论文中使用了8个Nvidia GV100 GPU来训练模型。  


### WaveFlow
**百度**  
参考论文：[WaveFlow: A Compact Flow-based Model for Raw Audio](https://arxiv.org/abs/1912.01219)  
来源：ICML 2020  
发表时间：2020.6.24  
github地址：https://github.com/L0SG/WaveFlow  
WaveFlow的模型比WaveGlow小15倍。  

### LPCNet
参考论文：[LPCNet: Improving Neural Speech Synthesis Through Linear Prediction](https://arxiv.org/abs/1810.11846)  
来源：ICASSP 2019  
发表时间：2018.10.28  


### MelGAN
参考论文：[MelGAN Generative Adversarial Networks for Conditional Waveform Synthesis](https://arxiv.org/abs/1910.06711)  
来源：NeurIPS 2019  
发表时间：2019.10.8  
CPU可以运行的很快，两倍的实时速率

### Multi-band MelGAN
**搜狗**  
参考论文：[Multi-band MelGAN: Faster Waveform Generation for High-Quality Text-to-Speech](https://arxiv.org/abs/2005.05106)  
来源：Interspeech 2020  
发表时间：2020.5.11  
**基于CPU的生成速度为实时的33倍**  

对MelGAN的改进有：  
- 增大了接受域，有利于语音的生成
- Multi-resolution STFT loss 代替了 Feature matching loss，更好地度量了真语音和假语音的差距
- 增加了multi-band processing

### 2.6 PGHI

### 2.7 Local Weighted Sum
